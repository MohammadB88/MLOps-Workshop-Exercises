# 5: Review the Experiments & Select the Best Model

## Objective
In this lab, we will:

* Review the performance of different models and runs
* Select the Model with the best performance

## Guide

The steps in this exercise will be carried out in the `"03_model_training.ipynb"` notebook.

# Review the Experiments & Select the Best Model
In this task, you'll review your logged experiments on ``MLflow`` to compare model runs based on their performance metrics. By analyzing the results, you'll identify the best-performing model configuration and select it for further evaluation or deployment.

The steps in this task will be caried out in the second notebook: `"04_model_registeration.ipynb"`

### step 1 - Set the MLflow Remote Tracking Server
ðŸ’¡ **Note:** **The link to the MLflow server will be provided during the workshop!**

You should replace the `MLFLOW_REMOTE_TRACKING_SERVER` with this provided URL.

### step 2 - Set a Dummy Name or your Firstname (It should be unique!)

ðŸ’¡ **Note:** There is only one instance of ``MLFlow server`` for all the participants. So in order to avoid any confusions, please make sure that you put an unique name!

You should replace the `YOUR_FIRSTNAME` with a dummy name or your firstname.

### Step 3 - Review the Experiments and their Results
At this step, you should just run the cell and review the output. 
This is basically, what we saw on the MLflow UI at the end of the last step.

### Step 4 - Select the Best-Performing experiment
We select the run (``run-ID``) which has performed the best, when we prompted in the notebook.

Please folow the instruction in the notebook to complete this task.