{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c71bd30",
   "metadata": {},
   "source": [
    "# 🚀 Module 3: Model Packaging and Deployment on Kubernetes\n",
    "\n",
    "In this module, we will:\n",
    "1. Build a REST API for model inference using FastAPI\n",
    "2. Create a Containerfile to containerize the service\n",
    "3. Deploy the container to a Kubernetes cluster (i.e. OpenShift)\n",
    "4. Load a Test Dataset\n",
    "5. Test the Model-API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5f8b0-e52c-4ca6-97c9-3dfb211c3441",
   "metadata": {},
   "source": [
    "## 🛠️ Create a REST API using FastAPI\n",
    "This API will load the model and expose an endpoint for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b897f9f-88ff-4ea8-bb8c-cc347123672b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./models/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./models/app.py\n",
    "# ./models/app.py\n",
    "import os\n",
    "from fastapi import FastAPI, HTTPException\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "from mlflow.pyfunc import PyFuncModel\n",
    "\n",
    "# ── 1. Read configuration from environment ──────────────────────────────\n",
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\") # e.g. \"https://mlflow_tracking_server.com\"\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\") # e.g. \"BikeSharingModel\" \n",
    "MODEL_VERSION = os.getenv(\"MODEL_VERSION\") # e.g. \"5\" \n",
    "\n",
    "if not MLFLOW_TRACKING_URI:\n",
    "    raise RuntimeError(\"MLFLOW_TRACKING_URI environment variable not set\")\n",
    "\n",
    "if not MODEL_VERSION:\n",
    "    raise RuntimeError(\"MODEL_VERSION environment variable not set!\")\n",
    "\n",
    "# ── 2. Connect to MLflow and load the model once at startup ─────────────\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "# load a specific version\n",
    "model_uri = f\"models:/{MODEL_NAME}/{MODEL_VERSION}\"\n",
    "\n",
    "model: PyFuncModel = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "# ── 3. API definition ───────────────────────────────────────────────────\n",
    "app = FastAPI(title=\"Bike-Sharing Predictor\",\n",
    "              description=f\"Served from {model_uri} at {MLFLOW_TRACKING_URI}\",\n",
    "              version=\"1.0.0\")\n",
    "\n",
    "# Health check model\n",
    "class HealthCheck(BaseModel):\n",
    "    status: str = \"OK\"\n",
    "\n",
    "@app.get(\"/health\", response_model=HealthCheck, status_code=status.HTTP_200_OK,\n",
    "         summary=\"Health check endpoint\")\n",
    "def health_check():\n",
    "    return HealthCheck(status=\"OK\")\n",
    "\n",
    "@app.get(\"/\", include_in_schema=False, summary=\"Root welcome or redirect\")\n",
    "def root():\n",
    "    # Option A: friendly message\n",
    "    return {\"message\": \"Hello! Please try /docs to see the available endpoints.\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(features: dict):\n",
    "    \"\"\"\n",
    "    Accepts a JSON object of feature names / values\n",
    "    and returns a single prediction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.DataFrame([features])\n",
    "        prediction = float(model.predict(df)[0])  # ensure JSON-serialisable\n",
    "        return {\"prediction\": prediction}\n",
    "    except Exception as exc:\n",
    "        raise HTTPException(status_code=400, detail=str(exc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5518853-7e7a-45dd-b7ad-92bbfc7d5798",
   "metadata": {},
   "source": [
    "## 📦 Containerize the FastAPI Application\n",
    "Create a Containerfile for the FastAPI app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b439cf-81d2-459d-8553-6e64fae590c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./models/Containerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./models/Containerfile\n",
    "# ./models/Containerfile\n",
    "FROM python:3.11-slim\n",
    "\n",
    "# ── Install OS dependencies (optional but helpful) ───────────────────────\n",
    "RUN apt-get update && apt-get install -y --no-install-recommends \\\n",
    "        build-essential         \\\n",
    "    && rm -rf /var/lib/apt/lists/*\n",
    "\n",
    "# ── Set workdir and copy application code ────────────────────────────────\n",
    "WORKDIR /app\n",
    "COPY app.py ./\n",
    "\n",
    "# ── Install Python requirements ──────────────────────────────────────────\n",
    "# mlflow pulls in scikit-learn, pandas, etc.  --no-cache-dir keeps image small\n",
    "RUN pip install --no-cache-dir fastapi uvicorn[standard] mlflow pandas\n",
    "\n",
    "# ── Environment variables with sensible defaults (override at runtime) ──\n",
    "\n",
    "# ── MLflow Tracking URI ────────────────────────────────────────────────\n",
    "# This is the URI of the MLflow Tracking Server where the model is registered\n",
    "# e.g. \"https://mlflow_tracking_server.com\"\n",
    "ENV MLFLOW_TRACKING_URI=\"\"\n",
    "\n",
    "# ── Model name ───────────────────────────────────────────── \n",
    "# This is the name of the model registered in MLflow\n",
    "# e.g. \"BikeSharingModel\"\n",
    "ENV MODEL_NAME=\"\"\n",
    "\n",
    "# ── Model version ────────────────────────────────────────────\n",
    "# This is the version of the model to load from MLflow.\n",
    "# e.g. \"1\"\n",
    "ENV MODEL_VERSION=\"\"\n",
    "\n",
    "# ── Entrypoint ───────────────────────────────────────────────────────────\n",
    "CMD [\"uvicorn\", \"app:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75104455",
   "metadata": {},
   "source": [
    "#### Congratulations! You have completed all the steps in task 5 (`Model Deploymet - Containerize the Endpoint-API`). \n",
    "#### Please go back to the instructions on the GitHub-Pages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf928e20",
   "metadata": {},
   "source": [
    "#### We will continue with the steps in task 6 (`Model Deploymet - Deploy on OpenShift Cluster`). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba913bcb-2f3a-41c3-92ce-13c77b157980",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 🚀 Deployment on OpenShift Cluster: Test the Model-API\n",
    "In this section, we deploy the trained machine learning model on an OpenShift cluster. The deployment includes deploying the image via a deployment manifest and exposing it using an internal service.\n",
    "\n",
    "- Deploy the Image Using k8s_deployment.yaml\n",
    "- Expose the Model Internally via a Service\n",
    "- Expose the Model Externally via a Route (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd891fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
